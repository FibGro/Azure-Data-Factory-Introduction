# Azure_Data_Factory_Covid

Practise with Azure Data Factory for Covid Database. 
- Ingest dataset (death cases and hospital admission) from http:// and also from Azure Blob Storage to Azure Data Lake Gen2 by using Azure Data Factory (pipelines) 
- Using Azure Data Flow to make several types of transformation (Source, Filter, Lookup, Pivot, Sink) of dataset, creating a pipeline and storage it in Azure Data Lake Gen2.
- Not able to perform HD Insight to transform the dataset due to the free subcription allowances.
- Create an interactive cluster in Databricks and then using Data Factory to execute transformation using notebook in job cluster.
- Performing copy activities from Data Lake to Azure SQL Database.
- By using Data Factory triggers to execute automation on the pipeline
- Monitoring Data Factory 
